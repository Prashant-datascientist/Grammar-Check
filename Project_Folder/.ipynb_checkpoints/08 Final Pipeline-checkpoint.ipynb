{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T07:17:43.076264Z",
     "start_time": "2023-07-28T07:17:36.492632Z"
    },
    "id": "7GDYXfQhKWbw"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense,RNN,Softmax\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Softmax\n",
    "from tensorflow.keras.optimizers import Adam,Nadam\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from nltk.translate.gleu_score import sentence_gleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T07:18:18.106048Z",
     "start_time": "2023-07-28T07:18:18.079849Z"
    },
    "id": "-V1b-YteL4ms"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utility'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10364\\2557762889.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutility\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utility'"
     ]
    }
   ],
   "source": [
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XkHrn5TLNDvL"
   },
   "outputs": [],
   "source": [
    "model = encoder_decoder(enc_vocab_size,dec_vocab_size,embedding_dim,lstm_size,input_length,batch_size,att_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y24HYU5NOsbk",
    "outputId": "322bdd94-206d-4b4b-bfe6-b035ced31daf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f0d7d7b4250>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('C:/Users/prash/Desktop/New_now100/data/Models/03 enc_dec_with_attention/03_enc_dec_with_attention')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ryNuPnadK55i"
   },
   "outputs": [],
   "source": [
    "def function1(input_sentence):\n",
    "    '''This function takes sentence as input and returns a grammatically correct sentence as output'''\n",
    "    corrc_wrd_idx_dict = tokenizer_dec.word_index\n",
    "    corrc_idx_wrd_dict = {v: k for k, v in corrc_wrd_idx_dict.items()}\n",
    "\n",
    "    input_sentence = tokenizer_enc.texts_to_sequences([input_sentence])[0]\n",
    "    initial_hidden_state = tf.zeros([1,192])\n",
    "    initial_cell_state = tf.zeros([1,192])\n",
    "    encoder_initial_state = [initial_hidden_state,initial_cell_state]\n",
    "    input_sentence = tf.keras.preprocessing.sequence.pad_sequences([input_sentence],maxlen=12,padding='post')\n",
    "    input_sentence = input_sentence[0]\n",
    "    enc_output, enc_state_h, enc_state_c = model.layers[0](np.expand_dims(input_sentence,0),encoder_initial_state)\n",
    "    pred = []\n",
    "    sentence = []\n",
    "    cur_vec = np.ones((1, 1),dtype='int')\n",
    "    attention_array = np.zeros([12,12])\n",
    "    for i in range(12):\n",
    "        output,dec_state_h, dec_state_c,att_weights,context_vector = model.layers[1].onestepdecoder(cur_vec, enc_output,enc_state_h, enc_state_c)\n",
    "        enc_state_h, enc_state_c = dec_state_h, dec_state_c\n",
    "        cur_vec = np.reshape(np.argmax(output), (1, 1))\n",
    "        if corrc_idx_wrd_dict[cur_vec[0][0]] == '<end>':\n",
    "            break\n",
    "        pred.append(cur_vec[0][0])\n",
    "        att_weights = tf.squeeze(att_weights)   \n",
    "        attention_array[i] = att_weights\n",
    "    for i in pred:\n",
    "        sentence.append(corrc_idx_wrd_dict[i])\n",
    "    return \" \".join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "l9P1kdJRZhSh",
    "outputId": "7f02b6d7-16e5-462d-a4f5-c1bc05374338"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'I heard it was a popular book in America .'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function1('I heard it was the popular book in America .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "73wePjQDaVpy"
   },
   "outputs": [],
   "source": [
    "def function2(file):\n",
    "    df = pd.read_csv(file)\n",
    "    glue_score_arr = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        reference = [df['correct'].iloc[i].split()]\n",
    "        pred = function1(df['incorrect'].iloc[i])\n",
    "        candidate = pred.split()\n",
    "        try:\n",
    "            glue_score_arr.append(sentence_gleu(reference, candidate))\n",
    "        except:\n",
    "            continue\n",
    "    return np.mean(glue_score_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJ5c5CDDaikR",
    "outputId": "4eb42bff-25d7-407b-c3d8-cad62c5294c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:34<00:00,  5.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5706688557748922"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function2('/content/drive/MyDrive/Self Case studies/CS02 Grammar Error Corrector/test_file.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
